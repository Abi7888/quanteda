% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cfm.R
\name{cfm}
\alias{cfm}
\alias{cfm.character}
\alias{cfm.corpus}
\alias{cfm.tokenizedTexts}
\title{create a context-feature co-occurrence matrix}
\usage{
cfm(x, ...)

\method{cfm}{tokenizedTexts}(x, context = c("document", "window"),
  count = c("frequency", "boolean", "weighted"), window = 5L,
  weights = rep(1, length(window)), span_sentence = TRUE, tri = TRUE, ...)

\method{cfm}{corpus}(x, ...)

\method{cfm}{character}(x, ...)
}
\arguments{
\item{x}{character vector, corpus, or tokenized texts from which to generate 
the context-feature co-occurrence matrix.}

\item{...}{not used here}

\item{context}{the context in which to consider term co-occurrence: 
\code{"document"} for co-occurrence counts within document; \code{"window"}
for co-occurrence within a defined window of words, which requires a 
postive integer value for \code{window}}

\item{count}{how to count co-occurrences:
\describe{
\item{\code{frequency}}{count the number of co-occurrences within the context}
\item{\code{boolean}}{count only the co-occurrence or not within the context, 
 irrespective of how many times it occurs}
\item{\code{weighted}}{count a weighted function of counts, typically as a 
function of distance from the target feature.  Only makes sense for \code{context = "window"}.}
}}

\item{window}{positive integer value for the size of a window on either side 
of the target feature, default is 5, meaning 5 words before and after the 
target feature}

\item{weights}{a vector of weights applied to each distance from 
\code{1:window}, strictly decreasing and of the same length as 
\code{length(weights)}}

\item{span_sentence}{if \code{FALSE}, then word windows will not span 
sentences}

\item{tri}{if \code{TRUE} return only upper triangle (including diagonal)}
}
\description{
Create a sparse context-feature co-occurrence matrix, measuring 
co-occurrences of features within a user-defined context. The context can be 
defined as a document or a window within a collection of documents, with an 
optional vector of weights applied to the co-occurrence counts.
}
\details{
The funciton \link{cfm} provides a very general implementation of a 
  "context-feature" matrix, consisting of a count of feature co-occurrence 
  within a defined context.  This context, following Momtazi et. al. (2010), 
  can be defined as the \emph{document}, \emph{sentences} within documents, 
  \emph{syntactic relationships} beteeen features (nouns within a sentence,
  for instance), or according to a \emph{window}.  When the context is a window, 
  a weighting function is typically applied that is a function of distance from the 
  target word (see Jurafsky and Martin 2015, Ch. 16).  
  
  \link{cfm} provides all of this functionality, returning a \eqn{V \times V} matrix
  (where \eqn{V} is the vocabulary size, returned by \code{\link{ntype}}).  Because
  this matrix is symmetric, the \code{tri = TRUE} option will only return the upper
  part of the matrix.
  
  Unlike some implementations of co-occurrences, \link{cfm} counts feature co-occurrences 
  with themselves, meaning that the diagonal will not be zero.
}
\examples{
# see http://bit.ly/29b2zOA
txt <- "A D A C E A D F E B A C E D"
cfm(txt, context = "window", window = 2)
cfm(txt, context = "window", window = 2, tri = FALSE)

# with multiple documents
txts <- c("a a b b c", "a c e", "e f g")
#### b IS DOUBLE COUNTED
cfm(txts, context = "document", count = "frequency")
#### DIAGONAL IS WRONG
cfm(txts, context = "document", count = "boolean")

txt <- c("The quick brown fox jumped over the lazy dog.",
         "The dog jumped and ate the fox.")
toks <- tokenize(toLower(txt), removePunct = TRUE)
cfm(toks, context = "document")
cfm(toks, context = "window", window = 3)
cfm(toks, context = "window", window = 2)
}
\author{
Kenneth Benoit (R) and Kohei Watanabe (C++)
}
\references{
Momtazi, S., Khudanpur, S., & Klakow, D. (2010). 
  "\href{https://www.lsv.uni-saarland.de/fileadmin/publications/SaeedehMomtazi-HLT_NAACL10.pdf}{A
   comparative study of word co-occurrence for term clustering in language 
  model-based sentence retrieval.}" \emph{Human Language Technologies: The 
  2010 Annual Conference of the North American Chapter of the ACL}, Los 
  Angeles, California, June 2010, pp. 325â€“328.
  
  Daniel Jurafsky & James H. Martin. (2015) \emph{Speech and Language 
  Processing}.  Draft of April 11, 2016. 
  \href{https://web.stanford.edu/~jurafsky/slp3/16.pdf}{Chapter 16, Semantics
  with Dense Vectors.}
}

